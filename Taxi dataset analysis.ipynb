{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression to predict tip category\n",
    "\n",
    "Obtain necessary data from the two datafiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846945\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "infile = open(\"nyc_data.csv\", 'r')    # open the file for reading\n",
    "infile2 = open(\"nyc_fare.csv\", 'r')\n",
    "\n",
    "reader = csv.reader(infile)\n",
    "reader2 = csv.reader(infile2)\n",
    "reader.next() #remove headers\n",
    "reader2.next()\n",
    "\n",
    "taxi_file = []\n",
    "taxi_file2 = []\n",
    "\n",
    "for line in reader:     \n",
    "    taxi_file.append(line)\n",
    "    \n",
    "nb = 0\n",
    "for line2 in reader2:                   # read through the CSV one line at a time\n",
    "    taxi_file2.append(line2)\n",
    "    \n",
    "print len(taxi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456019\n",
      "[1.0, 960.0, 3.28, 14.5, '2.8']\n"
     ]
    }
   ],
   "source": [
    "temp =[]\n",
    "data = []\n",
    "\n",
    "for line in taxi_file:\n",
    "    data_list = []\n",
    "    data_list.append(float(line[7]))\n",
    "    data_list.append(float(line[8]))\n",
    "    data_list.append(float(line[9]))\n",
    "    temp.append(data_list)\n",
    "    \n",
    "nb = 0\n",
    "for line2 in taxi_file2:                   # read through the CSV one line at a time\n",
    "    if line2[4] == 'CRD':\n",
    "        data.append(temp[nb]+ ([float(line2[5]) + float(line2[6]) + float(line2[7]) + float(line2[9])] + ([line2[8]])))\n",
    "    nb+=1\n",
    "    \n",
    "print len(data)\n",
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform tip value in categories and normalize numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996702277756\n",
      "1.99340455551\n",
      "2.99010683327\n",
      "3.98680911102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from __future__ import division\n",
    "\n",
    "x_mean = np.array([line[:4] for line in data]).mean(axis=0)\n",
    "x_std = np.array([line[:4] for line in data]).std(axis=0)\n",
    "\n",
    "y_mean = np.mean([float(d[4]) for d in data])\n",
    "y_low = y_mean * 2/5\n",
    "y_medium_low = y_low * 2\n",
    "y_medium = y_mean * 6/5\n",
    "y_medium_high = y_mean * 8/5\n",
    "\n",
    "print y_low\n",
    "print y_medium_low\n",
    "print y_medium\n",
    "print y_medium_high\n",
    "\n",
    "i=0\n",
    "for d in data:\n",
    "    data[i][0] = (d[0] - x_mean[0])/x_std[0]\n",
    "    data[i][1] = (d[1] - x_mean[1])/x_std[1]\n",
    "    data[i][2] = (d[2] - x_mean[2])/x_std[2]\n",
    "    data[i][3] = (d[3] - x_mean[3])/x_std[3]\n",
    "    if float(d[4]) < y_low:\n",
    "        data[i][4] = 'low'\n",
    "    elif float(d[4]) < y_medium_low:\n",
    "        data[i][4] = 'medium-low'\n",
    "    elif float(d[4]) < y_medium:\n",
    "        data[i][4] = 'medium'\n",
    "    elif float(d[4]) < y_medium_high:\n",
    "        data[i][4] = 'medium-high'\n",
    "    else:\n",
    "        data[i][4] = 'high'\n",
    "    i+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide in training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  364900\n",
      "test  91119\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for d in data:\n",
    "    rd = random.random()\n",
    "    if rd < 0.8:\n",
    "        train.append(d)\n",
    "    elif rd < 1.0:\n",
    "        test.append(d)\n",
    "        \n",
    "print 'train ',len(train)\n",
    "print 'test ',len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get input and output variables for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [line[:4] for line in train]\n",
    "y = [line[4] for line in train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform multivariate regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [[ -2.10517021e-02  -3.54842330e-03  -3.47314216e-03   2.60222124e+00]\n",
      " [  5.13792047e-02   3.19369123e-03  -6.65188665e-03  -2.22349328e-01]\n",
      " [ -6.23260445e-03   4.74636826e-03   9.74433832e-03  -2.54902155e-01]\n",
      " [ -3.42967358e-03   3.76919278e-03  -6.23007388e-03   2.17493061e-01]\n",
      " [  6.09494690e-03  -5.34665271e-03  -1.03110534e-02  -3.46317581e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(x, y)\n",
    "\n",
    "print'Coefficients: ', regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = [line[:4] for line in test]\n",
    "y_test = [line[4] for line in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Get prediction for the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get performance score on testing set:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581931320581\n"
     ]
    }
   ],
   "source": [
    "print regr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $r^2$ score is not that bad, but there is room for improvement. Maybe the logisitic regression approach is not the best: let's try with a decision tree classifier.\n",
    "\n",
    "For this, we will wome back to the first dataset, using the number of passengers, the trip duration, the trip distance, the amount of the trip, based only on trips paid with credit cards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit a decision tree to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the score of the decision tree for the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594102217979\n"
     ]
    }
   ],
   "source": [
    "print clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also try with a random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63198674261131049"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "forest = ensemble.RandomForestClassifier()\n",
    "forest.fit(x,y)\n",
    "forest.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The $r^2$ score hasn't been improved so much, but there is a nice improvement with a random forst classifier.Now, maybe we can try to add different features, such as the day of the week and the time of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49952274252615503, 0.0069147838584908842, -0.0014624231423751382, 0.036605255018071575, 'medium', 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "\n",
    "weekdays = []\n",
    "hours = []\n",
    "\n",
    "for d in taxi_file2:\n",
    "    if d[4] == 'CRD':\n",
    "        daytime = d[3]\n",
    "        date, time = daytime.split(\" \")\n",
    "        year, month, day = date.split(\"-\")\n",
    "        hour, minute, second = time.split(\":\")\n",
    "        my_date = datetime.date(int(year), int(month), int(day))\n",
    "        weekdays.append(my_date.weekday())\n",
    "        hours.append(hour)  \n",
    "    \n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb2 = preprocessing.LabelBinarizer()\n",
    "\n",
    "hours = lb.fit_transform(hours).tolist()\n",
    "weekdays = lb2.fit_transform(weekdays).tolist()\n",
    "\n",
    "nb = 0\n",
    "\n",
    "for d in data:\n",
    "    data[nb] = data[nb] + hours[nb]\n",
    "    data[nb] = data[nb] + weekdays[nb]\n",
    "    nb += 1\n",
    "    \n",
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a new dataset to work with, we can create new training and testing sets, and try a logisitic regression, a decision tree, and a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  364987\n",
      "test  91032\n",
      "R2 for Logistic Regression:  0.577796818701\n",
      "R2 for Decision Tree:  0.565021091484\n",
      "R2 for Random Forest Classifier:  0.636863959926\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for d in data:\n",
    "    rd = random.random()\n",
    "    if rd < 0.8:\n",
    "        train.append(d)\n",
    "    elif rd < 1.0:\n",
    "        test.append(d)\n",
    "        \n",
    "print 'train ',len(train)\n",
    "print 'test ',len(test)\n",
    "\n",
    "x = [line[:4] + line[5:] for line in train]\n",
    "y = [line[4] for line in train]\n",
    "\n",
    "x_test = [line[:4]+ line[5:] for line in test]\n",
    "y_test = [line[4] for line in test]\n",
    "\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(x, y)\n",
    "print 'R2 for Logistic Regression: ', regr.score(x_test, y_test)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x, y)\n",
    "print 'R2 for Decision Tree: ', clf.score(x_test, y_test) \n",
    "\n",
    "forest = ensemble.RandomForestClassifier()\n",
    "forest.fit(x,y)\n",
    "print 'R2 for Random Forest Classifier: ', forest.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By takink the pick-up time into account, we can achieve a $r^2$ score of 68% with a random forest classifier; which is now pretty good. However, we could try one last modification by taking the pick-up and drop-off locations into account.\n",
    "\n",
    "As usual, let's start by creating a new dataset to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456019\n",
      "[-73.955925, 40.781887, -73.963181, 40.777832000000004]\n",
      "[-0.49952274252615503, 0.0069147838584908842, -0.0014624231423751382, 0.036605255018071575, 'medium', 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, -73.955925, 40.781887, -73.963181, 40.777832000000004]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "\n",
    "locations = []\n",
    "nb = 0\n",
    "\n",
    "for d in taxi_file2:\n",
    "    if d[4] == 'CRD':\n",
    "        locations.append([float(taxi_file[nb][10])] + [float(taxi_file[nb][11])] + [float(taxi_file[nb][12])] + [float(taxi_file[nb][13])])\n",
    "        nb+=1\n",
    "        \n",
    "print len(locations)\n",
    "print locations[0]\n",
    "\n",
    "nb = 0\n",
    "\n",
    "for d in data:\n",
    "    data[nb] = data[nb] + locations[nb]\n",
    "    nb += 1\n",
    "    \n",
    "print data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's look at the scores for the different methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  365025\n",
      "test  90994\n",
      "R2 for Logistic Regression:  0.578554629976\n",
      "R2 for Decision Tree:  0.561751324263\n",
      "R2 for Random Forest Classifier:  0.673934545135\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for d in data:\n",
    "    rd = random.random()\n",
    "    if rd < 0.8:\n",
    "        train.append(d)\n",
    "    elif rd < 1.0:\n",
    "        test.append(d)\n",
    "        \n",
    "print 'train ',len(train)\n",
    "print 'test ',len(test)\n",
    "\n",
    "x = [line[:4] + line[5:] for line in train]\n",
    "y = [line[4] for line in train]\n",
    "\n",
    "x_test = [line[:4]+ line[5:] for line in test]\n",
    "y_test = [line[4] for line in test]\n",
    "\n",
    "regr = linear_model.LogisticRegression()\n",
    "regr.fit(x, y)\n",
    "print 'R2 for Logistic Regression: ', regr.score(x_test, y_test)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x, y)\n",
    "print 'R2 for Decision Tree: ', clf.score(x_test, y_test) \n",
    "\n",
    "forest = ensemble.RandomForestClassifier()\n",
    "forest.fit(x,y)\n",
    "print 'R2 for Random Forest Classifier: ', forest.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing the different techniques and the different attributes that could be taken into account, it looks like the best we can achieve is 67% with a random forest classifier taking into account all the attributes we have.\n",
    "\n",
    "This is not bad, and it might not be possible to improve more because we would need data that we don't have access to: the amount of the tip might depend a lot on the client's social background such as his age, his profession, his marital status..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
